### 第一章：簡介與基礎概念

#### 1.1 什麼是 Web 爬蟲？
- **定義與功能**：
  - 爬蟲（Web crawler）是一種自動化程式，用於在互聯網上抓取網頁信息。
  - 主要功能包括收集網頁數據、建立搜尋引擎索引、監測網站更新等。

- **爬蟲的工作原理**：
  - 發送HTTP請求到目標網站，獲取HTML響應。
  - 解析HTML文檔，提取需要的數據或URL。
  - 遞歸或迭代地重複這個過程，構建網絡地圖或抓取所需數據。

#### 1.2 爬蟲的應用與重要性
- **搜尋引擎**：
  - 爬蟲是搜尋引擎的核心組件，通過爬取和索引網頁，使用戶能夠查找和訪問信息。

- **商業應用**：
  - 爬蟲可以用於市場研究、競爭情報收集、價格比較等商業活動中，幫助企業做出基於數據的決策。

- **監控與警報**：
  - 監控網站變化或事件發生，如新聞聚合、天氣預報、社交媒體分析等。

#### 1.3 HTTP 協議與網頁結構基礎
- **HTTP基礎**：
  - HTTP（HyperText Transfer Protocol）是網絡傳輸協議，爬蟲通過HTTP協議與網站進行通信和數據交換。

- **HTML結構**：
  - HTML（HyperText Markup Language）定義了網頁的結構和內容，爬蟲通常根據HTML標記和層次來解析網頁。

#### 1.4 Robots.txt 檔案與網站禮節
- **Robots.txt檔案**：
  - Robots.txt是一個文本文件，用於指導搜索引擎爬蟲訪問網站的規則和限制。

- **網站禮節**：
  - 爬蟲應該遵守Robots.txt中的規定，尊重網站的使用條款，避免對網站造成過度負擔或干擾正常訪問。

這一章節旨在為讀者建立起對Web爬蟲基礎概念的清晰理解，包括其定義、工作原理、應用領域以及與HTTP協議、HTML結構和Robots.txt檔案的基本關係。